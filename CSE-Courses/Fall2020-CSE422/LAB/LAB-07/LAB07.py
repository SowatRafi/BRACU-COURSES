# -*- coding: utf-8 -*-
"""lab07_updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Due-dV4n41ZUviKzHx8nXlzvQ04-GJeS
"""

# N-L-0
import pandas as pd
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split

vltr = pd.read_csv('/content/breast cancer classification dataset.csv')
vltr.tail()

# For Logistic Regression (N-L-1)
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer

vltr.shape

vltr.isnull().sum()

vltr = vltr.drop(['Unnamed: 32'], axis = 1)
vltr.shape

impute = SimpleImputer(missing_values=np.nan, strategy='mean')
impute.fit(vltr[ ['fractal_dimension_worst'] ])
impute.fit(vltr[ ['radius_mean'] ])
vltr['fractal_dimension_worst'] = impute.transform(vltr[ ['fractal_dimension_worst'] ])
vltr['radius_mean'] = impute.transform(vltr[ ['radius_mean'] ])

vltr.isnull().sum()

vltr

vltr.info()

vltr['diagnosis'].unique()

# N-L-2
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
vltr['diagnosis'] = encoder.fit_transform(vltr['diagnosis'])
print(vltr['diagnosis'])

y = vltr['diagnosis']
x = vltr.drop(columns='diagnosis')

# Split the Data into 80% for Training and 20% for Testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Train the model
model = LogisticRegression()
model.fit(x_train, y_train)
predictions = model.predict(x_test)
print(predictions)

score_1 = accuracy_score(y_test, predictions)
print (score_1)

vltr

vltr['diagnosis'].unique()

# N-L-3
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

clf = DecisionTreeClassifier(criterion='entropy',random_state=1)
clf.fit(x_train, y_train)
y_pred = clf.predict(x_test)
score=accuracy_score(y_test,y_pred)
print(score)

# N-L-4
from sklearn import tree
import matplotlib.pyplot as plt

figure, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (4, 4), dpi=300)
tree.plot_tree(clf,
               feature_names = x.columns,
               class_names=['1','0'],
               filled = True);

# N-L-5
import matplotlib.pyplot as plt

figure = plt.figure()
width = 0.35
ax = figure.add_axes([0, 0, 1, 1])
label = ['Logistic recursion', 'Recursive Tree']
percentage = [score_1, score]
ax.bar(label, percentage)
plt.show()

vltr